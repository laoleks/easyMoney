{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "630abd2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "from http import client\n",
    "from urllib import response\n",
    "from slack_sdk import WebClient\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "client = WebClient(token =\"\") # ¡¡You need to insert a Slack app token here for this script to work!!\n",
    "\n",
    "objective = 100000000000 # Max number of messages that will possibly be checked\n",
    "query_size = 200 # Max number of messages per query\n",
    "queries = int(objective/query_size) # Number of queries that will be attempted at most.\n",
    "cursor = None # Marker for the data the next query will ask\n",
    "for i in range(queries):\n",
    "    \n",
    "    response = client.conversations_history( # This method queries a given channel and stores the response in a variable. It usually needs to be executed several times \n",
    "        channel=\"C033KQ2V37V\", # because the maximum query size is 1000.\n",
    "        limit=query_size,\n",
    "        cursor=cursor,\n",
    "        oldest=1654030800\n",
    "\n",
    "    )\n",
    "    conversation_history = response[\"messages\"] # We store the message data into a new variable \n",
    "    \n",
    "    \n",
    "    if i == 0: # The following lines create a list or append new results to the growing list of messages\n",
    "        full_conversation = conversation_history\n",
    "    else:\n",
    "        full_conversation = full_conversation + conversation_history\n",
    "\n",
    "    print(i*query_size) # Prints the progress of the querying\n",
    "    if response[\"response_metadata\"] != None: # The result of the query tells us exactly the next cursor we should use to get the next batch of messages\n",
    "        cursor = response[\"response_metadata\"][\"next_cursor\"]\n",
    "    else: # Once there are no more messages to query, the loop stops\n",
    "        break  \n",
    "\n",
    "\n",
    "with open(\"reviews_jun_2022-2023.json\", \"w\") as f: # We open a new file in json format (it is basically a dictionary or a list)\n",
    "        json.dump(full_conversation, f) # We load our full results there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6c734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "with open(\"reviews_jun_2022-2023.json\", \"r\") as f: # We open the file we created in extract.py\n",
    "    e = json.load(f) # We load its content into a variable. The content is a list of dictionaries. They are the messages and their data\n",
    "\n",
    "l = []\n",
    "for i in e: # We add tuples to a list specifying if they belong to airtable or appbot. We do that by checking if the word appbot or airtable appear in each mesaage.\n",
    "    if isinstance(i[\"text\"], dict): # If you study the structure of the data in the file, you can deduce how this loop works.\n",
    "        l+=[i]\n",
    "    else:\n",
    "        if \"airtable\" in i[\"text\"]:\n",
    "            l+=[(i[\"ts\"],json.dumps(i), i[\"text\"], \"airtable\")]\n",
    "        elif \"appbot\" in i[\"text\"]:\n",
    "            l+=[(i[\"ts\"],json.dumps(i), i[\"text\"], \"appbot\")]\n",
    "            #print(i)\n",
    "        else:\n",
    "            if \"blocks\" in i.keys():\n",
    "                if \"appbot\" in \"\".join([o[\"text\"][\"text\"] for o in i[\"blocks\"] if \"text\" in o.keys() ]):\n",
    "                    l+=[(i[\"ts\"],json.dumps(i), \"\".join([o[\"text\"][\"text\"] if \"text\" in o.keys() else o[\"elements\"][0][\"text\"] if \"elements\" in o.keys() and \"text\" in o[\"elements\"][0].keys() else \"\" for o in i[\"blocks\"]  ]), \"appbot\")]\n",
    "                    \n",
    "\n",
    "data = pd.DataFrame(l, columns = [\"ts\", \"original_record\",\"text\", \"bot\"]) # We transform the labeled data into a new pandas Dataframe\n",
    "\n",
    "# The following lines extract every single field we need from the message raw text, using references like emojis and words.\n",
    "# It uses an additional special universal language known as Regex, which is essential for parsing text.\n",
    "\n",
    "data[\"strings\"] = data[\"text\"].str.extract(\":speaking_head_in_silhouette:(.*)\")\n",
    "data[\"strings\"] = data[\"strings\"].fillna(\"\")\n",
    "\n",
    "data[\"appbot\"] = data[\"text\"].str.extract(r\"[★☆]{5}\\n(.*)\\n\", re.DOTALL)\n",
    "data.loc[data[\"appbot\"].str.contains(\"English Translation\").fillna(False),\"appbot\"] = \"\"\n",
    "data[\"appbot\"] = data[\"appbot\"].fillna(\"\")\n",
    "\n",
    "data[\"appbot_eng\"] = data[\"text\"].str.extract(r\"English Translation_\\n(.*)-{19}\\n\", re.DOTALL) \n",
    "data.loc[~data[\"appbot_eng\"].str.contains(\"\").fillna(False),\"appbot_eng\"] = \"\"\n",
    "\n",
    "data[\"Opinion\"] = data[\"appbot\"] + data[\"strings\"]\n",
    "data[\"Opinion\"] = data[\"Opinion\"] + data[\"appbot_eng\"]\n",
    "\n",
    "data[\"sentiment_airtable\"] = data[\"text\"].str.extract(\"Sentiment:  (.*)\").fillna(\"\")\n",
    "data[\"sentiment_appbot\"] = data[\"text\"].str.extract(\":.+circle: ([A-Z][a-z]+)\").fillna(\"\")\n",
    "\n",
    "data[\"sentiment\"] = data[\"sentiment_appbot\"] + data[\"sentiment_airtable\"]\n",
    "\n",
    "data = data.drop([\"strings\", \"appbot\", \"appbot_eng\", \"sentiment_airtable\", \"sentiment_appbot\"], axis = 1)\n",
    "\n",
    "data[\"topic\"] = data[\"text\"].str.extract(\"Topic :jigsaw:  (.*)\").fillna(\"\")\n",
    "\n",
    "# We convert the timestamp of the message from a number to a readable date and time.\n",
    "data[\"ts\"] = [datetime.datetime.fromtimestamp(float(i)).strftime(\"%Y-%m-%d %H:%M:%S\") for i in data[\"ts\"]]\n",
    "\n",
    "data.to_csv(\"reviews_jun_2022-2023_raw.csv\") # We export the raw results to an excel\n",
    "\n",
    "data = data[data[\"Opinion\"] != \"\"] # We remove the completely empty opinion cells because Appbot messages usually consist of a general info message and \n",
    "# an opinion message. We only want the opinion messages.\n",
    "\n",
    "data = data.drop([\"original_record\", \"text\"], axis = 1) # We remove the raw columns from the data\n",
    "\n",
    "\n",
    "data.to_csv(\"reviews_jun_2022-2023_clean.csv\") # We export a cleaner alternative dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b4f0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
